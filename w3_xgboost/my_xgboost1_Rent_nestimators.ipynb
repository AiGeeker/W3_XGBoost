{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Parameter Tuning for Rent Listing Inqueries\n",
    "\n",
    "Rental Listing Inquiries数据集是Kaggle平台上的一个分类竞赛任务，需要根据公寓的特征来预测其受欢迎程度（用户感兴趣程度分为高、中、低三类）。其中房屋的特征x共有14维，响应值y为用户对该公寓的感兴趣程度。评价标准为logloss。 数据链接：https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 直接调用xgboost内嵌的cv寻找最佳的参数n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>price_bathrooms</th>\n",
       "      <th>price_bedrooms</th>\n",
       "      <th>room_diff</th>\n",
       "      <th>room_num</th>\n",
       "      <th>Year</th>\n",
       "      <th>...</th>\n",
       "      <th>walk</th>\n",
       "      <th>walls</th>\n",
       "      <th>war</th>\n",
       "      <th>washer</th>\n",
       "      <th>water</th>\n",
       "      <th>wheelchair</th>\n",
       "      <th>wifi</th>\n",
       "      <th>windows</th>\n",
       "      <th>work</th>\n",
       "      <th>interest_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>3000</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>5465</td>\n",
       "      <td>2732.5</td>\n",
       "      <td>1821.666667</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.7388</td>\n",
       "      <td>-74.0018</td>\n",
       "      <td>2850</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>1425.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.7539</td>\n",
       "      <td>-73.9677</td>\n",
       "      <td>3275</td>\n",
       "      <td>1637.5</td>\n",
       "      <td>1637.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>40.8241</td>\n",
       "      <td>-73.9493</td>\n",
       "      <td>3350</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bathrooms  bedrooms  latitude  longitude  price  price_bathrooms  \\\n",
       "0        1.5         3   40.7145   -73.9425   3000           1200.0   \n",
       "1        1.0         2   40.7947   -73.9667   5465           2732.5   \n",
       "2        1.0         1   40.7388   -74.0018   2850           1425.0   \n",
       "3        1.0         1   40.7539   -73.9677   3275           1637.5   \n",
       "4        1.0         4   40.8241   -73.9493   3350           1675.0   \n",
       "\n",
       "   price_bedrooms  room_diff  room_num  Year       ...        walk  walls  \\\n",
       "0      750.000000       -1.5       4.5  2016       ...           0      0   \n",
       "1     1821.666667       -1.0       3.0  2016       ...           0      0   \n",
       "2     1425.000000        0.0       2.0  2016       ...           0      0   \n",
       "3     1637.500000        0.0       2.0  2016       ...           0      0   \n",
       "4      670.000000       -3.0       5.0  2016       ...           0      0   \n",
       "\n",
       "   war  washer  water  wheelchair  wifi  windows  work  interest_level  \n",
       "0    0       0      0           0     0        0     0               1  \n",
       "1    0       0      0           0     0        0     0               2  \n",
       "2    0       0      0           0     0        0     0               0  \n",
       "3    0       0      0           0     0        0     0               2  \n",
       "4    1       0      0           0     0        0     0               2  \n",
       "\n",
       "[5 rows x 225 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to where the data lies\n",
    "#dpath = './data/'\n",
    "train = pd.read_csv(\"RentListingInquries_FE_train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49352 entries, 0 to 49351\n",
      "Columns: 225 entries, bathrooms to interest_level\n",
      "dtypes: float64(7), int64(218)\n",
      "memory usage: 84.7 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>price_bathrooms</th>\n",
       "      <th>price_bedrooms</th>\n",
       "      <th>room_diff</th>\n",
       "      <th>room_num</th>\n",
       "      <th>Year</th>\n",
       "      <th>...</th>\n",
       "      <th>walk</th>\n",
       "      <th>walls</th>\n",
       "      <th>war</th>\n",
       "      <th>washer</th>\n",
       "      <th>water</th>\n",
       "      <th>wheelchair</th>\n",
       "      <th>wifi</th>\n",
       "      <th>windows</th>\n",
       "      <th>work</th>\n",
       "      <th>interest_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49352.00000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>4.935200e+04</td>\n",
       "      <td>4.935200e+04</td>\n",
       "      <td>4.935200e+04</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.21218</td>\n",
       "      <td>1.541640</td>\n",
       "      <td>40.741545</td>\n",
       "      <td>-73.955716</td>\n",
       "      <td>3.830174e+03</td>\n",
       "      <td>1.697863e+03</td>\n",
       "      <td>1.657567e+03</td>\n",
       "      <td>-0.329460</td>\n",
       "      <td>2.753820</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.186477</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.028165</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>1.616895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50142</td>\n",
       "      <td>1.115018</td>\n",
       "      <td>0.638535</td>\n",
       "      <td>1.177912</td>\n",
       "      <td>2.206687e+04</td>\n",
       "      <td>1.100477e+04</td>\n",
       "      <td>7.817996e+03</td>\n",
       "      <td>0.947732</td>\n",
       "      <td>1.446091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055412</td>\n",
       "      <td>0.019618</td>\n",
       "      <td>0.389495</td>\n",
       "      <td>0.101625</td>\n",
       "      <td>0.021109</td>\n",
       "      <td>0.165446</td>\n",
       "      <td>0.044969</td>\n",
       "      <td>0.031814</td>\n",
       "      <td>0.030846</td>\n",
       "      <td>0.626035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-118.271000</td>\n",
       "      <td>4.300000e+01</td>\n",
       "      <td>2.150000e+01</td>\n",
       "      <td>4.300000e+01</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.728300</td>\n",
       "      <td>-73.991700</td>\n",
       "      <td>2.500000e+03</td>\n",
       "      <td>1.225000e+03</td>\n",
       "      <td>1.066667e+03</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.751800</td>\n",
       "      <td>-73.977900</td>\n",
       "      <td>3.150000e+03</td>\n",
       "      <td>1.500000e+03</td>\n",
       "      <td>1.383417e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.774300</td>\n",
       "      <td>-73.954800</td>\n",
       "      <td>4.100000e+03</td>\n",
       "      <td>1.850000e+03</td>\n",
       "      <td>1.962500e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>44.883500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.490000e+06</td>\n",
       "      <td>2.245000e+06</td>\n",
       "      <td>1.496667e+06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         bathrooms      bedrooms      latitude     longitude         price  \\\n",
       "count  49352.00000  49352.000000  49352.000000  49352.000000  4.935200e+04   \n",
       "mean       1.21218      1.541640     40.741545    -73.955716  3.830174e+03   \n",
       "std        0.50142      1.115018      0.638535      1.177912  2.206687e+04   \n",
       "min        0.00000      0.000000      0.000000   -118.271000  4.300000e+01   \n",
       "25%        1.00000      1.000000     40.728300    -73.991700  2.500000e+03   \n",
       "50%        1.00000      1.000000     40.751800    -73.977900  3.150000e+03   \n",
       "75%        1.00000      2.000000     40.774300    -73.954800  4.100000e+03   \n",
       "max       10.00000      8.000000     44.883500      0.000000  4.490000e+06   \n",
       "\n",
       "       price_bathrooms  price_bedrooms     room_diff      room_num     Year  \\\n",
       "count     4.935200e+04    4.935200e+04  49352.000000  49352.000000  49352.0   \n",
       "mean      1.697863e+03    1.657567e+03     -0.329460      2.753820   2016.0   \n",
       "std       1.100477e+04    7.817996e+03      0.947732      1.446091      0.0   \n",
       "min       2.150000e+01    4.300000e+01     -5.000000      0.000000   2016.0   \n",
       "25%       1.225000e+03    1.066667e+03     -1.000000      2.000000   2016.0   \n",
       "50%       1.500000e+03    1.383417e+03      0.000000      2.000000   2016.0   \n",
       "75%       1.850000e+03    1.962500e+03      0.000000      4.000000   2016.0   \n",
       "max       2.245000e+06    1.496667e+06      8.000000     13.500000   2016.0   \n",
       "\n",
       "            ...                walk         walls           war        washer  \\\n",
       "count       ...        49352.000000  49352.000000  49352.000000  49352.000000   \n",
       "mean        ...            0.003080      0.000385      0.186477      0.009361   \n",
       "std         ...            0.055412      0.019618      0.389495      0.101625   \n",
       "min         ...            0.000000      0.000000      0.000000      0.000000   \n",
       "25%         ...            0.000000      0.000000      0.000000      0.000000   \n",
       "50%         ...            0.000000      0.000000      0.000000      0.000000   \n",
       "75%         ...            0.000000      0.000000      0.000000      0.000000   \n",
       "max         ...            1.000000      1.000000      1.000000      2.000000   \n",
       "\n",
       "              water    wheelchair          wifi       windows          work  \\\n",
       "count  49352.000000  49352.000000  49352.000000  49352.000000  49352.000000   \n",
       "mean       0.000446      0.028165      0.002026      0.001013      0.000952   \n",
       "std        0.021109      0.165446      0.044969      0.031814      0.030846   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       interest_level  \n",
       "count    49352.000000  \n",
       "mean         1.616895  \n",
       "std          0.626035  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          2.000000  \n",
       "75%          2.000000  \n",
       "max          2.000000  \n",
       "\n",
       "[8 rows x 225 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['interest_level']\n",
    "\n",
    "train = train.drop([ \"interest_level\"], axis=1)\n",
    "X_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练样本6w+，交叉验证太慢，用train_test_split估计模型性能\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train_part, X_val, y_train_part, y_val = train_test_split(X_train, y_train, train_size = 0.33,random_state = 0)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#直接调用xgboost内嵌的交叉验证（cv），可对连续的n_estimators参数进行快速交叉验证\n",
    "#而GridSearchCV只能对有限个参数进行交叉验证\n",
    "def modelfit(alg, X_train, y_train, cv_folds=None, early_stopping_rounds=10):\n",
    "    xgb_param = alg.get_xgb_params()\n",
    "#     print(xgb_param)\n",
    "    xgb_param['num_class'] = 3\n",
    "    \n",
    "    #直接调用xgboost，而非sklarn的wrapper类\n",
    "    xgtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "        \n",
    "    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], \n",
    "                      folds =cv_folds, metrics='mlogloss', early_stopping_rounds=early_stopping_rounds)\n",
    "    print(cvresult)\n",
    "    cvresult.to_csv('1_nestimators.csv', index_label = 'n_estimators')\n",
    "    \n",
    "    #最佳参数n_estimators\n",
    "    n_estimators = cvresult.shape[0]\n",
    "    \n",
    "    # 采用交叉验证得到的最佳参数n_estimators，训练模型\n",
    "    alg.set_params(n_estimators = n_estimators)\n",
    "    alg.fit(X_train, y_train, eval_metric='mlogloss')\n",
    "        \n",
    "    #Predict training set:\n",
    "    #train_predprob = alg.predict_proba(X_train)\n",
    "    #logloss = log_loss(y_train, train_predprob)\n",
    "\n",
    "   #Print model report:\n",
    "   # print (\"logloss of train :\" )\n",
    "   # print logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     train-mlogloss-mean  train-mlogloss-std  test-mlogloss-mean  \\\n",
      "0               1.036909            0.000196            1.037798   \n",
      "1               0.985289            0.000450            0.987105   \n",
      "2               0.940985            0.000386            0.943599   \n",
      "3               0.902897            0.000453            0.906374   \n",
      "4               0.869778            0.000154            0.874006   \n",
      "5               0.840821            0.000409            0.845817   \n",
      "6               0.815198            0.000494            0.821004   \n",
      "7               0.793006            0.000834            0.799591   \n",
      "8               0.773080            0.000926            0.780386   \n",
      "9               0.755129            0.000676            0.763199   \n",
      "10              0.739314            0.000645            0.748047   \n",
      "11              0.725137            0.000636            0.734666   \n",
      "12              0.712397            0.000504            0.722667   \n",
      "13              0.700836            0.000437            0.711802   \n",
      "14              0.690454            0.000379            0.702182   \n",
      "15              0.681068            0.000653            0.693599   \n",
      "16              0.672940            0.000816            0.686167   \n",
      "17              0.665379            0.000870            0.679375   \n",
      "18              0.658640            0.000898            0.673394   \n",
      "19              0.652208            0.000889            0.667673   \n",
      "20              0.646373            0.000901            0.662580   \n",
      "21              0.640928            0.001136            0.657852   \n",
      "22              0.635822            0.001043            0.653489   \n",
      "23              0.631102            0.001043            0.649429   \n",
      "24              0.626718            0.001094            0.645734   \n",
      "25              0.622642            0.001141            0.642348   \n",
      "26              0.618860            0.001135            0.639346   \n",
      "27              0.615325            0.001105            0.636573   \n",
      "28              0.612061            0.001048            0.633986   \n",
      "29              0.608924            0.000928            0.631551   \n",
      "..                   ...                 ...                 ...   \n",
      "208             0.463949            0.001164            0.573741   \n",
      "209             0.463501            0.001175            0.573691   \n",
      "210             0.463079            0.001326            0.573642   \n",
      "211             0.462632            0.001407            0.573592   \n",
      "212             0.462145            0.001410            0.573572   \n",
      "213             0.461725            0.001375            0.573573   \n",
      "214             0.461278            0.001410            0.573577   \n",
      "215             0.460939            0.001350            0.573579   \n",
      "216             0.460454            0.001325            0.573512   \n",
      "217             0.459931            0.001330            0.573453   \n",
      "218             0.459510            0.001293            0.573444   \n",
      "219             0.459033            0.001367            0.573448   \n",
      "220             0.458580            0.001384            0.573424   \n",
      "221             0.458123            0.001447            0.573395   \n",
      "222             0.457668            0.001427            0.573378   \n",
      "223             0.457219            0.001456            0.573337   \n",
      "224             0.456791            0.001511            0.573381   \n",
      "225             0.456384            0.001570            0.573341   \n",
      "226             0.455993            0.001506            0.573303   \n",
      "227             0.455574            0.001461            0.573242   \n",
      "228             0.455110            0.001496            0.573256   \n",
      "229             0.454637            0.001524            0.573196   \n",
      "230             0.454223            0.001564            0.573162   \n",
      "231             0.453879            0.001608            0.573094   \n",
      "232             0.453496            0.001599            0.573064   \n",
      "233             0.453124            0.001558            0.573062   \n",
      "234             0.452698            0.001524            0.572984   \n",
      "235             0.452283            0.001501            0.572920   \n",
      "236             0.451934            0.001563            0.572883   \n",
      "237             0.451493            0.001556            0.572841   \n",
      "\n",
      "     test-mlogloss-std  \n",
      "0             0.000230  \n",
      "1             0.000766  \n",
      "2             0.001004  \n",
      "3             0.000990  \n",
      "4             0.000894  \n",
      "5             0.000950  \n",
      "6             0.001393  \n",
      "7             0.002013  \n",
      "8             0.002198  \n",
      "9             0.002169  \n",
      "10            0.002176  \n",
      "11            0.002270  \n",
      "12            0.002241  \n",
      "13            0.002231  \n",
      "14            0.002269  \n",
      "15            0.002275  \n",
      "16            0.002175  \n",
      "17            0.002079  \n",
      "18            0.002017  \n",
      "19            0.002041  \n",
      "20            0.002137  \n",
      "21            0.002055  \n",
      "22            0.002197  \n",
      "23            0.002395  \n",
      "24            0.002313  \n",
      "25            0.002296  \n",
      "26            0.002195  \n",
      "27            0.002145  \n",
      "28            0.002280  \n",
      "29            0.002249  \n",
      "..                 ...  \n",
      "208           0.004219  \n",
      "209           0.004228  \n",
      "210           0.004204  \n",
      "211           0.004261  \n",
      "212           0.004268  \n",
      "213           0.004249  \n",
      "214           0.004254  \n",
      "215           0.004283  \n",
      "216           0.004315  \n",
      "217           0.004335  \n",
      "218           0.004399  \n",
      "219           0.004410  \n",
      "220           0.004422  \n",
      "221           0.004377  \n",
      "222           0.004433  \n",
      "223           0.004441  \n",
      "224           0.004394  \n",
      "225           0.004376  \n",
      "226           0.004436  \n",
      "227           0.004461  \n",
      "228           0.004495  \n",
      "229           0.004479  \n",
      "230           0.004453  \n",
      "231           0.004458  \n",
      "232           0.004466  \n",
      "233           0.004496  \n",
      "234           0.004478  \n",
      "235           0.004446  \n",
      "236           0.004495  \n",
      "237           0.004488  \n",
      "\n",
      "[238 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#params = {\"objective\": \"multi:softprob\", \"eval_metric\":\"mlogloss\", \"num_class\": 9}\n",
    "xgb1 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,  #数值大没关系，cv会自动返回合适的n_estimators\n",
    "        max_depth=6,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample = 0.5,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=0.7,\n",
    "        objective= 'multi:softprob',\n",
    "        seed=3)\n",
    "\n",
    "modelfit(xgb1, X_train, y_train, cv_folds=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 0.7,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 238,\n",
       " 'nthread': 1,\n",
       " 'objective': 'multi:softprob',\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': 3,\n",
       " 'silent': 1,\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.get_xgb_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shnu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvresult = pd.DataFrame.from_csv('1_nestimators.csv')\n",
    "        \n",
    "# plot\n",
    "test_means = cvresult['test-mlogloss-mean']\n",
    "test_stds = cvresult['test-mlogloss-std'] \n",
    "        \n",
    "train_means = cvresult['train-mlogloss-mean']\n",
    "train_stds = cvresult['train-mlogloss-std'] \n",
    "\n",
    "x_axis = range(0, cvresult.shape[0])\n",
    "        \n",
    "pyplot.errorbar(x_axis, test_means, yerr=test_stds ,label='Test')\n",
    "pyplot.errorbar(x_axis, train_means, yerr=train_stds ,label='Train')\n",
    "pyplot.title(\"XGBoost n_estimators vs Log Loss\")\n",
    "pyplot.xlabel( 'n_estimators' )\n",
    "pyplot.ylabel( 'Log Loss' )\n",
    "pyplot.legend()\n",
    "pyplot.savefig( 'n_estimators1_1.png' )\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: 238\n"
     ]
    }
   ],
   "source": [
    "# 最佳参数n_estimators\n",
    "n_estimators = cvresult.shape[0]\n",
    "print(\"Best n_estimators:\", n_estimators)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
